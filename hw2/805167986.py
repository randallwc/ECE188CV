# -*- coding: utf-8 -*-
"""805167986.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Qmv0wE2xBDYv9ojNwimJ49fsqoVf0no6

# **PSET 2**

These are some of the libraries/modules you will require for this homework.
"""

# Commented out IPython magic to ensure Python compatibility.
# %load_ext autoreload
# %autoreload 2
# %matplotlib inline
import numpy as np
import scipy
from PIL import Image
import skimage
from skimage import data
from skimage.transform import warp, AffineTransform
import matplotlib.pyplot as plt
import copy
import os

"""These are some functions which will be useful throught the homework to (1) display a single grayscale image, (2) display multiple images using subplots."""

def display_gray(x: np.array, normalized:bool = False):
    plt.figure(figsize=(10,10))
    if not normalized:
        plt.imshow(x,cmap='gray',vmin=0,vmax=1)
    else:
        plt.imshow(x/x.max(),cmap='gray',vmin=0,vmax=1)

def display_axis(ax: plt.axis, x: np.array, title: str, normalized:bool = False):
    if not normalized:
        ax.imshow(x,cmap='gray',vmin=0,vmax=1)
    else:
        ax.imshow(x/x.max(),cmap='gray',vmin=0,vmax=1)
    ax.set_title(title,size=18)

def display_axis_bw(ax: plt.axis, x: np.array, title: str, normalized:bool = False, fig = None):
    if not normalized:
        imax = ax.imshow(x,cmap='gray',vmin=0,vmax=1)
    else:
        imax = ax.imshow(x/x.max(),cmap='gray',vmin=0,vmax=1)
    ax.set_title(title,size=18)
    fig.colorbar(imax,ax=ax)

def display_axis_color(ax: plt.axis, x: np.array, title: str, normalized:bool = False, fig = None):
    if not normalized:
        imax = ax.imshow(x,cmap='coolwarm',vmin=0,vmax=1)
    else:
        imax = ax.imshow(x/x.max(),cmap='coolwarm',vmin=0,vmax=1)
    ax.set_title(title,size=18)
    fig.colorbar(imax,ax=ax)

"""# Question 2

### Blob Detection

In this question, you will be using the Laplacian of Gaussian Filter to perform blob detection. Using the previous parts of the question you should have an analytical expression for the Laplacian of Gaussian. You will be using that result to design a LoG filter. You will then be using that filter to detect blobs of different scales in the image by varying the standard deviation parameter.
"""

# Copy paste your conv2D function from the previous homework here.
def conv2D(image: np.array, kernel: np.array = None):
    # get the shape of the kernel
    krow, kcol = kernel.shape
    assert(krow == kcol)

    # get shape of image
    irow, icol = image.shape

    # pad the image
    pad_image = np.pad(image, krow//2, mode='constant')

    # make output image
    out = np.zeros(image.shape)

    # flip the kernel
    flipped_kernel = np.flipud(np.fliplr(kernel))

    # loop through and compute the convolution
    for i in range(irow):
        for j in range(icol):
            # dot product between kernel and sub image
            out[i][j] = np.sum(pad_image[i:i+krow,j:j+krow] * flipped_kernel)
    return out

"""We use the two functions below to create blobs of different sizes. You will have 5 different sizes of blobs in the image below. You will have to tune the standard deviation of your LoG filter such that you get the maximum response."""

def make_circle(img: np.array, x: int, y: int, radius: int):
    for i in range(img.shape[0]):
        for j in range(img.shape[1]):
            if np.sqrt((x-i)**2 + (y-j)**2) < 1.0*radius:
                img[i,j]=1
    return img

def draw_circle(img, y, radius):
    rad_buffer = radius + 5
    start = rad_buffer+5
    end = 255 - rad_buffer - 5
    centers = np.linspace(start, end, int((end-start)/(2*rad_buffer)))
    for c in centers:
        c = int(c)
        make_circle(img, y, c, radius)
    return img

blob_img = np.zeros((256,256))
blob_img = draw_circle(blob_img, 25, 5)
blob_img = draw_circle(blob_img, 50, 10)
blob_img = draw_circle(blob_img, 85, 15)
blob_img = draw_circle(blob_img, 130, 20)
blob_img = draw_circle(blob_img, 200, 35)

display_gray(blob_img)

img = copy.deepcopy(blob_img)

"""#### **Answer 2.5**

For this sub-part, you will be writing a function `log_filter(size, sigma)`, which takes as input the size of the LoG filter and the sigma, and returns a scale-normalized LoG filter.

Copy paste your solution in the cell below on Overleaf for Question 2.5.
"""

# Write your answer in this cell.
def log_filter(size: int, sigma: float):
    norm = 1 / (2 * np.pi * sigma**4)
    radius = size // 2
    ss = sigma**2
    result = np.zeros((size, size))
    for i in range(size):
        for j in range(size):
            x = i-radius
            y = j-radius
            exp = np.exp(-(x**2 + y**2) / (2*ss))
            second_term = x**2 + y**2 - 2*ss
            result[i, j] = exp * second_term * norm
    return result

"""As you might have seen above, the image blobs have 5 different scales. Hence you have to find 5 `sigma` values which will give maximum response when the LoG filter is convolved with the image. You may want to use the results from the class lectures to find the values for `sigma`. To visualize maximum response we will be plotting the filtered images using a color map where blue color would correspond to smaller values and red color would correspond to higher values.

#### **Answer 2.6**

Tune the values of the 5 `sigmas`, so that you get the maximum response for each scale. So, `sigma_1` should be such that you get the maximum response for the smallest blobs, `sigma_5` should give you the maximum response for the largest blobs.

Write the values of the 5 `sigmas` you get here on Overleaf.
"""

sigma_1 = 5/np.sqrt(2)
log_1 = log_filter(21, sigma_1)
sigma_2 = 10/np.sqrt(2)
log_2 = log_filter(31, sigma_2)
sigma_3 = 15/np.sqrt(2)
log_3 = log_filter(41, sigma_3)
sigma_4 = 20/np.sqrt(2)
log_4 = log_filter(51, sigma_4)
sigma_5 = 35/np.sqrt(2)
log_5 = log_filter(81, sigma_5)

"""#### **Answer 2.7**

In this sub-part, you will visualize the LoG filters.

Upload the saved image on Overleaf for Question 2.7.
"""

fig, ax = plt.subplots(1,5,figsize=(1 + 5*4.5,4))
display_axis_bw(ax[0],log_1,'Sigma1',normalized=True,fig=fig)
display_axis_bw(ax[1],log_2,'Sigma2',normalized=True,fig=fig)
display_axis_bw(ax[2],log_3,'Sigma3',normalized=True,fig=fig)
display_axis_bw(ax[3],log_4,'Sigma4',normalized=True,fig=fig)
display_axis_bw(ax[4],log_5,'Sigma5',normalized=True,fig=fig)
fig.tight_layout()
os.makedirs('Data/Solutions', exist_ok=True)
fig.savefig('Data/Solutions/question_2_7.pdf', format='pdf', bbox_inches='tight')

"""Convolve the image with the 5 filters. Note that we multiply the filters with -1 so that the maximum response is positive."""

log_conv_1 = conv2D(img, -log_1)
log_conv_2 = conv2D(img, -log_2)
log_conv_3 = conv2D(img, -log_3)
log_conv_4 = conv2D(img, -log_4)
log_conv_5 = conv2D(img, -log_5)

"""#### **Answer 2.8**

In this sub-part, you will visualize the blob detection results. We also plot the colorbar with each image. You should use that to tune the values for `sigma`.

Upload the saved image on Overleaf for Question 2.8.
"""

fig, ax = plt.subplots(2,3,figsize=(1 + 3*6,2*6))
display_axis_bw(ax[0,0],img,'Original Image',fig=fig)
display_axis_color(ax[0,1],log_conv_1,'Sigma1',fig=fig)
display_axis_color(ax[0,2],log_conv_2,'Sigma2',fig=fig)
display_axis_color(ax[1,0],log_conv_3,'Sigma3',fig=fig)
display_axis_color(ax[1,1],log_conv_4,'Sigma4',fig=fig)
display_axis_color(ax[1,2],log_conv_5,'Sigma5',fig=fig)
fig.tight_layout()
fig.savefig('Data/Solutions/question_2_8.pdf', format='pdf', bbox_inches='tight')

"""# Question 3

## Corner Detection

In this question, you will be implementing the Harris corner detector. Corners serve as useful features in images for a variety of reasons: they are salient, well localized, and invariant to a variety of transformations (illumination, rotation, and scale changes). The Harris corner detector also possesses some of these invariances (rotation and intensity shift) but is not invariant to image and intensity scaling. Nevertheless, the Harris corner detector is still a popular method for detecting corners in images.

A grayscale test image (normalized to be in [0, 1]) containing some squares and a warped checkerboard is constructed below.
"""

# Sheared checkerboard
tform = AffineTransform(scale=(1.3, 1.1), rotation=1, shear=0.7,
                        translation=(110, 30))
image = warp(data.checkerboard()[:90, :90], tform.inverse,
             output_shape=(200, 310))

# Two squares
image[30:80, 200:250] = 1
image[80:130, 250:300] = 1

display_gray(image)

"""### Computing Image Gradients

The first step in the Harris corner detector is to compute the image gradients. While there are a variety of different methods to compute gradients, you will use the Sobel filter, which is defined below for the x and y directions.
"""

sobel_x = np.array([[1, 0, -1],
                    [2, 0, -2],
                    [1, 0, -1]])
sobel_y = np.array([[1, 2, 1],
                    [0, 0, 0],
                    [-1, -2, -1]])

"""After defining the Sobel filters, you need to apply them to obtain the gradients. Complete a function ```compute_image_gradient(image)``` that returns the horizontal (along the x direction) and vertical (along the y direction) image gradients using the provided Sobel filters. For this function (and all convolutions that follow), use the ```conv2D(image, kernel)``` function, which you should copy paste into the cell at the beginning of Question 2.

#### **Answer 3.1**

Copy paste your solution in the cell below on Overleaf for Question 3.1.
"""

# Write your code in this cell.
def compute_image_gradient(image: np.array):
    return conv2D(image, sobel_x), conv2D(image, sobel_y)

"""Display the absolute gradient along the horizontal and vertical directions and their sum. You should observe that the gradient in the horizontal (x-direction) is unable to capture the horizontal edges while the gradient in the vertical (y-direction) is unable to capture the vertical edges. Both gradients capture the diagonal edges, but they may appear dimmer than the horizontal and vertical edges.

#### **Answer 3.2**

Execute the cell below and copy the saved image on Overleaf for Question 3.2.
"""

fig, ax = plt.subplots(1,3,figsize=(1 + 3*4.5,4))
img_gradient_x, img_gradient_y = compute_image_gradient(image)
display_axis(ax[0], np.abs(img_gradient_x), 'Gradient-X')
display_axis(ax[1], np.abs(img_gradient_y), 'Gradient-Y')
display_axis(ax[2], np.abs(img_gradient_x) + np.abs(img_gradient_y), 'Gradient-Sum')
fig.tight_layout()
os.makedirs('Data/Solutions', exist_ok=True)
fig.savefig('Data/Solutions/question_3_2.pdf', format='pdf', bbox_inches='tight')

"""### **Computing the Covariance Matrix**

After computing the gradients, the Harris corner detector then computes the covariance matrix of the gradients (see lecture 5 slide 26). Complete the function ```grad_covariance(image, size)``` that computes each pixel's covariance matrix using the ```size x size``` window centered at the pixel. This function should return three matrices $I_{xx}, I_{xy}, I_{yy}$ containing the top-left, diagonal, and bottom-right terms, respectively, of every pixel's covariance matrix. When computing the covariance, you do not need to subtract the means of the image gradients. The average filter is provided below as a useful function.
"""

# This is the standard box filter which computes the mean of all the pixels inside the filter.
def average_filter(size: int):
    assert size%2 == 1
    return 1.0 * np.ones((size,size))/(size**2)

"""#### **Answer 3.3**

Copy paste your solution in the cell below on Overleaf for Question 3.3.
"""

# Write your code in this cell.
def grad_covariance(image: np.array, size: int):
    a = average_filter(size)
    dx, dy = compute_image_gradient(image)
    Ixx, Ixy, Iyy = conv2D(dx**2, a), conv2D(dx*dy, a), conv2D(dy**2, a)
    return Ixx, Ixy, Iyy

"""### **Harris Response Function**

Finally, the Harris corner detector uses the covariance matrix to compute a response function, which is then thresholded to obtain the locations of the corners. Complete the function ```harris_response(image, k, size)``` which computes the Harris response function (see lecture 5 slide 43, Harris & Stephens (1988)) for an image using a ```size x size``` window around every pixel. The parameter ```k``` corresponds to the parameter in the Harris response function.

#### **Answer 3.4**

Copy paste your solution in the cell below on Overleaf for Question 3.4.
"""

# Write your code in this cell.
def harris_response(image: np.array, k: float, size: int):
    irow, icol = image.shape
    ixx, ixy, iyy = grad_covariance(image, size)
    h = lambda r,c: ixx[r,c]*iyy[r,c] - ixy[r,c]**2 - k * (ixx[r,c]+iyy[r,c])**2
    return np.array([[h(r,c) for c in range(icol)] for r in range(irow)])

"""#### **Answer 3.5**

Execute the cell below and copy the saved image on Overleaf for Question 3.5. The cell below finds every pixel location where the Harris response function is above a certain threshold and then shows the locations of these pixels (the corner detections) in cyan.
"""

coords = np.argwhere(harris_response(image, 0.05, 3) > 0.02)
fig, ax = plt.subplots()
ax.imshow(image, cmap=plt.cm.gray)
ax.plot(coords[:, 1], coords[:, 0], color='cyan', marker='o',
        linestyle='None', markersize=6)
ax.axis((0, 310, 200, 0))
fig.tight_layout()
plt.show()
fig.savefig('Data/Solutions/question_3_5.pdf', format='pdf', bbox_inches='tight')

"""### **Non-Maximum Suppression**

You should observe from the above image that all corners are detected. However, some corners are detected multiple times, which is due to simply thresholding the Harris response. To suppress multiple detections, you will implement, in steps, a function ```non_max_suppression(harris_response, distance, threshold)``` that applies non-maximum suppression to the Harris corner response and returns the remaining corner detections.

Non-maximum suppression works as follows: 
1. Threshold the Harris response map to obtain the pixel locations where the response is greater than a certain threshold. These pixel locations form our candidate corner detections.
2. Sort these detections based on maximum response value.
3. Go through the sorted detections in order and for each detection, remove other detections that are within a certain Euclidean distance from the current detection. This step suppresses detections that are not local maxima.

You will implement the three steps of non-maximum suppression in order. First, complete the function ```threshold_harris_response(harris_response, threshold)```, which returns the indices of the Harris response map corresponding to values that are greater than some threshold.

#### **Answer 3.6**

Copy paste your solution in the cell below on Overleaf for Question 3.6.
"""

def threshold_harris_response(harris_response: np.array, threshold: float):
    return np.argwhere(harris_response > threshold)

"""Then, complete the function ```sort_detections(candidate_detections, harris_response)```, which returns the candidate detections sorted based on maximum Harris response value.

#### **Answer 3.7**

Copy paste your solution in the cell below on Overleaf for Question 3.7.
"""

# Write your code in this cell.
def sort_detections(candidate_detections: np.array, harris_response: np.array):
    k = lambda x: harris_response[x[0],x[1]]
    return sorted(candidate_detections, key=k,reverse=True)

"""The final step is to go through the sorted detections and suppress detections that are not local maxima. Complete the function ```local_max(sorted_detections, distance)```, which goes through the sorted detections and returns only the detections that are local maxima (using local neighborhoods defined by a Euclidean distance threshold ```distance```).

A function that computes Euclidean distance between two points is provided below for convenience.
"""

def l2_distance(p1: np.array, p2: np.array):
    return np.linalg.norm(p1 - p2, ord=2)

"""#### **Answer 3.8**

Copy paste your solution in the cell below on Overleaf for Question 3.8.
"""

# Write your code in this cell.
def local_max(sorted_detections: np.array, distance: float):
    lm = []
    while sorted_detections:
        t = sorted_detections.pop(0)
        if not any(l2_distance(t,d) < distance for d in lm):
            lm.append(t)
    return np.asarray(lm)

"""Now, combine the three previously implemented functions to complete the function ```non_max_suppression(harris_response, distance, threshold)```, which applies non-maximum suppression to the Harris corner response and returns the remaining corner detections as a NumPy array of (row, col) locations.

#### **Answer 3.9**

Copy paste your solution in the cell below on Overleaf for Question 3.9.
"""

# Write your code in this cell.
def non_max_suppression(harris_response: np.array, distance: float, threshold: float):
    candidate_detections = threshold_harris_response(harris_response, threshold)
    sorted_detections = sort_detections(candidate_detections, harris_response)
    return local_max(sorted_detections, distance)

"""#### **Answer 3.10**

Execute the cell below and copy the saved image on Overleaf for Question 3.10. The cell below runs non-maximum suppression on the Harris response map and then shows the locations of the corner detections in cyan. Duplicate corner detections should now be removed.
"""

coords = non_max_suppression(harris_response(image, 0.05, 3), 10.0, 0.02)
fig, ax = plt.subplots()
ax.imshow(image, cmap=plt.cm.gray)
ax.plot(coords[:, 1], coords[:, 0], color='cyan', marker='o',
        linestyle='None', markersize=6)
ax.axis((0, 310, 200, 0))
fig.tight_layout()
plt.show()
fig.savefig('Data/Solutions/question_3_10.pdf', format='pdf', bbox_inches='tight')